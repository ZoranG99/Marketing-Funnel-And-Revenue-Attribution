{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32b696ab",
   "metadata": {},
   "source": [
    "### Data Acquisition & Initial Global Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eddb7201",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aa9772f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Data ---\n",
      "All 11 tables loaded successfully.\n",
      "\n",
      "--- DATASET OVERVIEW ---\n",
      "                        Table    Rows  Cols  Missing Values  Duplicates\n",
      "0                      orders   99441     8            4908           0\n",
      "1                 order_items  112650     7               0           0\n",
      "2                     sellers    3095     4               0           0\n",
      "3                    products   32951    10            1838           0\n",
      "4        category_translation      71     2               0           0\n",
      "5                   customers   99441     5               0           0\n",
      "6                 geolocation   19015     5               0           0\n",
      "7              order_payments  103886     5               0           0\n",
      "8               order_reviews   99224     7          145903           0\n",
      "9   marketing_qualified_leads    8000     4              60           0\n",
      "10               closed_deals     842    14            3300           0\n",
      "\n",
      "--- THE BRIDGE ANALYSIS ---\n",
      "Sellers in Marketing Funnel: 842\n",
      "Sellers in Project 1 Data: 3095\n",
      "MATCHING SELLERS (The Bridge): 380\n",
      "\n",
      "--- KEY COLUMNS FOR JOINS ---\n",
      "Marketing Leads Columns: ['mql_id', 'first_contact_date', 'landing_page_id', 'origin']\n",
      "Closed Deals Columns: ['mql_id', 'seller_id', 'sdr_id', 'sr_id', 'won_date', 'business_segment', 'lead_type', 'lead_behaviour_profile', 'has_company', 'has_gtin', 'average_stock', 'business_type', 'declared_product_catalog_size', 'declared_monthly_revenue']\n"
     ]
    }
   ],
   "source": [
    "# 1. SETUP PATHS\n",
    "path_processed = \"../../data/processed/Ecommerce-Logistics-And-Revenue-Optimization_processed/\"\n",
    "path_raw = \"../../data/raw/\"\n",
    "\n",
    "# List of all files based on your screenshot\n",
    "processed_files = [\n",
    "    'orders.csv', 'order_items.csv', 'sellers.csv', 'products.csv', \n",
    "    'category_translation.csv', 'customers.csv', 'geolocation.csv', \n",
    "    'order_payments.csv', 'order_reviews.csv'\n",
    "]\n",
    "raw_files = [\n",
    "    'olist_marketing_qualified_leads_dataset.csv', \n",
    "    'olist_closed_deals_dataset.csv'\n",
    "]\n",
    "\n",
    "# 2. LOAD ALL DATA INTO A DICTIONARY\n",
    "dfs = {}\n",
    "\n",
    "print(\"--- Loading Data ---\")\n",
    "for f in processed_files:\n",
    "    name = f.replace('.csv', '')\n",
    "    dfs[name] = pd.read_csv(os.path.join(path_processed, f))\n",
    "\n",
    "for f in raw_files:\n",
    "    name = f.replace('olist_', '').replace('_dataset.csv', '')\n",
    "    dfs[name] = pd.read_csv(os.path.join(path_raw, f))\n",
    "print(\"All 11 tables loaded successfully.\\n\")\n",
    "\n",
    "# 3. GLOBAL SUMMARY TABLE\n",
    "summary_data = []\n",
    "for name, df in dfs.items():\n",
    "    summary_data.append({\n",
    "        \"Table\": name,\n",
    "        \"Rows\": df.shape[0],\n",
    "        \"Cols\": df.shape[1],\n",
    "        \"Missing Values\": df.isnull().sum().sum(),\n",
    "        \"Duplicates\": df.duplicated().sum()\n",
    "    })\n",
    "\n",
    "df_summary = pd.DataFrame(summary_data)\n",
    "print(\"--- DATASET OVERVIEW ---\")\n",
    "print(df_summary)\n",
    "\n",
    "# 4. INSPECT THE \"BRIDGE\" (The most important part)\n",
    "# We want to see how many sellers from the Funnel exist in the Sales data\n",
    "funnel_sellers = dfs['closed_deals']['seller_id'].unique()\n",
    "sales_sellers = dfs['sellers']['seller_id'].unique()\n",
    "\n",
    "bridge_count = len(set(funnel_sellers).intersection(set(sales_sellers)))\n",
    "\n",
    "print(\"\\n--- THE BRIDGE ANALYSIS ---\")\n",
    "print(f\"Sellers in Marketing Funnel: {len(funnel_sellers)}\")\n",
    "print(f\"Sellers in Project 1 Data: {len(sales_sellers)}\")\n",
    "print(f\"MATCHING SELLERS (The Bridge): {bridge_count}\")\n",
    "\n",
    "# 5. CHECKING COLUMN NAMES FOR MERGING\n",
    "print(\"\\n--- KEY COLUMNS FOR JOINS ---\")\n",
    "print(f\"Marketing Leads Columns: {dfs['marketing_qualified_leads'].columns.tolist()}\")\n",
    "print(f\"Closed Deals Columns: {dfs['closed_deals'].columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dbdc8f",
   "metadata": {},
   "source": [
    "### Marketing Funnel Cleaning & Seller Bridge Isolation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "350e0771",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Cleaned funnel exported to: ../../data/processed/\n",
      "Bridge Sellers Isolated: 380\n"
     ]
    }
   ],
   "source": [
    "# 1. MERGE THE MARKETING FUNNEL\n",
    "# We use a left join to keep all Leads, even if they didn't close (useful for Conversion Rate analysis)\n",
    "df_funnel = pd.merge(dfs['marketing_qualified_leads'], dfs['closed_deals'], on='mql_id', how='left')\n",
    "\n",
    "# 2. CONVERT DATES\n",
    "date_cols = ['first_contact_date', 'won_date']\n",
    "for col in date_cols:\n",
    "    df_funnel[col] = pd.to_datetime(df_funnel[col])\n",
    "\n",
    "# 3. FILL MISSING VALUES\n",
    "df_funnel['origin'] = df_funnel['origin'].fillna('unknown')\n",
    "df_funnel['business_segment'] = df_funnel['business_segment'].fillna('unknown')\n",
    "df_funnel['business_type'] = df_funnel['business_type'].fillna('unknown')\n",
    "\n",
    "# 4. ISOLATE THE BRIDGE SELLERS\n",
    "# Get the list of IDs that exist in both datasets\n",
    "bridge_seller_ids = set(dfs['closed_deals']['seller_id']).intersection(set(dfs['sellers']['seller_id']))\n",
    "\n",
    "# Create a flag in our funnel to identify these \"Project 1 Matching\" sellers\n",
    "df_funnel['is_bridge_seller'] = df_funnel['seller_id'].isin(bridge_seller_ids)\n",
    "\n",
    "# 5. EXPORT THE CLEANED FILES\n",
    "# Note: Using your requested path\n",
    "export_path = \"../../data/processed/\"\n",
    "\n",
    "df_funnel.to_csv(f\"{export_path}cleaned_marketing_funnel.csv\", index=False)\n",
    "\n",
    "print(f\"Success! Cleaned funnel exported to: {export_path}\")\n",
    "print(f\"Bridge Sellers Isolated: {len(bridge_seller_ids)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e050760",
   "metadata": {},
   "source": [
    "### Data Integrity Check & Revenue Attribution Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "395c2d75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- CLEANING VALIDATION ---\n",
      "Nulls in 'origin': 0\n",
      "Nulls in 'business_segment': 0\n",
      "Date Type for 'won_date': object\n",
      "\n",
      "--- BRIDGE DATA HEALTH (380 Sellers) ---\n",
      "Unique Sellers: 380\n",
      "Top 5 Marketing Origins:\n",
      "origin\n",
      "organic_search    113\n",
      "paid_search       101\n",
      "unknown            85\n",
      "direct_traffic     31\n",
      "social             31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Top 5 Business Segments:\n",
      "business_segment\n",
      "health_beauty                      45\n",
      "household_utilities                44\n",
      "home_decor                         44\n",
      "construction_tools_house_garden    32\n",
      "audio_video_electronics            31\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Total Order Rows for our Bridge Sellers: 5044\n",
      "Total Revenue from Bridge Sellers: $676,851.48\n"
     ]
    }
   ],
   "source": [
    "# 1. LOAD THE CLEANED FILE WE JUST CREATED\n",
    "df_cleaned_funnel = pd.read_csv(\"../../data/processed/cleaned_marketing_funnel.csv\")\n",
    "\n",
    "print(\"--- CLEANING VALIDATION ---\")\n",
    "# Check 1: Nulls in critical marketing columns\n",
    "print(f\"Nulls in 'origin': {df_cleaned_funnel['origin'].isnull().sum()}\")\n",
    "print(f\"Nulls in 'business_segment': {df_cleaned_funnel['business_segment'].isnull().sum()}\")\n",
    "\n",
    "# Check 2: Date Conversion Success\n",
    "print(f\"Date Type for 'won_date': {df_cleaned_funnel['won_date'].dtype}\")\n",
    "\n",
    "# Check 3: The Bridge Breakdown\n",
    "bridge_subset = df_cleaned_funnel[df_cleaned_funnel['is_bridge_seller'] == True]\n",
    "print(f\"\\n--- BRIDGE DATA HEALTH (380 Sellers) ---\")\n",
    "print(f\"Unique Sellers: {bridge_subset['seller_id'].nunique()}\")\n",
    "print(f\"Top 5 Marketing Origins:\\n{bridge_subset['origin'].value_counts().head(5)}\")\n",
    "print(f\"\\nTop 5 Business Segments:\\n{bridge_subset['business_segment'].value_counts().head(5)}\")\n",
    "\n",
    "# Check 4: Revenue Data availability (Previewing the join)\n",
    "# Let's see if our Bridge Sellers have actual sales in the order_items table\n",
    "sales_check = dfs['order_items'][dfs['order_items']['seller_id'].isin(bridge_subset['seller_id'])]\n",
    "print(f\"\\nTotal Order Rows for our Bridge Sellers: {len(sales_check)}\")\n",
    "print(f\"Total Revenue from Bridge Sellers: ${sales_check['price'].sum():,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1356ae76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
